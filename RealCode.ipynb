{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call Norvig Spelling Corrector \n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open('big.txt').read()))\n",
    "'''print (len(WORDS))\n",
    "print (sum(WORDS.values()))\n",
    "print (WORDS.most_common()[0:20])'''\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "\"\"\"def corrections(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    condidate_words = candidates(word)\n",
    "    for cword in condidate_words:\n",
    "        print(word, P(cword))\"\"\"\n",
    "\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make detect words file to reference list\n",
    "#with open('badwords - key.txt') as f:\n",
    "with open('bdk.txt') as f:\n",
    "    #mylist = list(f)\n",
    "    reflist = [line.rstrip('\\n') for line in f]\n",
    "    #print(reflist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recieve input from YouTube API\n",
    "import json\n",
    "with open('usertest.json', encoding = \"utf8\") as f:\n",
    "    s = f.read()\n",
    "#print(s)\n",
    "    d = json.loads(s)\n",
    "#type(d)\n",
    "#for user in d['user']:\n",
    "    #print(user['id'],user['messagedetails'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arsehole\n",
      "2\n",
      "a\n",
      "really\n",
      "love\n",
      "you\n",
      "0\n",
      "you\n",
      "re\n",
      "dick\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#make new JSON file (edit messagedetails)\n",
    "with open('usermessage.json', mode = 'w', encoding = \"utf8\") as f:\n",
    "    f.write(json.dumps(d))\n",
    "    for user in d['user']:\n",
    "#clean number to text\n",
    "        user['messagedetails'] = user['messagedetails'].replace(\"0\", \"o\")\n",
    "        user['messagedetails'] = user['messagedetails'].replace(\"1\", \"i\")\n",
    "        user['messagedetails'] = user['messagedetails'].replace(\"3\", \"e\")\n",
    "        user['messagedetails'] = user['messagedetails'].replace(\"4\", \"a\")\n",
    "        user['messagedetails'] = user['messagedetails'].replace(\"5\", \"s\")\n",
    "        user['messagedetails'] = user['messagedetails'].replace(\"7\", \"t\")\n",
    "        user['messagedetails'] = user['messagedetails'].replace(\"+\", \"t\")\n",
    "        user['messagedetails'] = user['messagedetails'].replace(\"!\", \"t\")\n",
    "        user['messagedetails'] = user['messagedetails'].replace(\"_\", \" \")\n",
    "        user['messagedetails'] = user['messagedetails'].replace(\"-\", \" \")\n",
    "        user['messagedetails'] = user['messagedetails'].replace(\"'\", \" \")\n",
    "        \n",
    "        #print(user['messagedetails'])\n",
    "        \n",
    "#tokenize text \n",
    "        list_sentence = user['messagedetails'].split(\" \")\n",
    "        for i in list_sentence :\n",
    "            correction(i)\n",
    "            print(correction(i))\n",
    "            if correction(i) in reflist:\n",
    "                user['attempt'] = user['attempt'] + 1\n",
    "        print(user['attempt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"user\": [{\"id\": 1, \"messagedetails\": \"asrehole\", \"attempt\": 1}, {\"id\": 2, \"messagedetails\": \"I really love you\", \"attempt\": 0}, {\"id\": 3, \"messagedetails\": \"you re dcik\", \"attempt\": 1}]}\n"
     ]
    }
   ],
   "source": [
    "with open('usermessage.json', encoding = \"utf8\") as g:\n",
    "    a = g.read()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
